{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannaribaspeeters/NLP-ETH/blob/main/context_free_parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac50491",
      "metadata": {
        "id": "cac50491"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this practical part of the assignment, you will implement a model that takes a sentence as input and predicts the most likely CFG parse tree given that sentence:\n",
        "$$\n",
        "\\mathbf{t} = \\text{argmax}_\\mathbf{t}P(\\mathbf{t}|\\mathbf{s})\n",
        "$$\n",
        "\n",
        "\n",
        "You will do this by converting the words into embeddings, and then implementing the CKY algorithm on top of an LSTM which you will train end-to-end."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "Please run the following cell to install the necessary dependencies for this notebook."
      ],
      "metadata": {
        "id": "qikEanUG5tFC"
      },
      "id": "qikEanUG5tFC"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dynet\n",
        "!pip install svgling"
      ],
      "metadata": {
        "id": "HDZd3lnK5u34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea574aab-a00c-4b41-a90f-e8abeaeeb378"
      },
      "id": "HDZd3lnK5u34",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dynet\n",
            "  Downloading dyNET-2.1.2-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dynet) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from dynet) (0.29.33)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, please add [this folder](https://drive.google.com/drive/folders/1FgT2bQdH0eCDDaqkDGk7hORUUDGd6a9t?usp=sharing) to your google drive, and then run the following cell:"
      ],
      "metadata": {
        "id": "OEeO7orj5xdz"
      },
      "id": "OEeO7orj5xdz"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/nlp-h2022-parsing'"
      ],
      "metadata": {
        "id": "ZX7mMf0Z5z85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53660423-856e-4178-9758-ef5cdf800f6b"
      },
      "id": "ZX7mMf0Z5z85",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/nlp-h2022-parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842646d2",
      "metadata": {
        "id": "842646d2"
      },
      "source": [
        "# 1. Training Data\n",
        "\n",
        "In this section, you will download, interact with, and clean the data which you will use to train and test your model. We will be using the Penn Treebank, an corpus of sentences annotated with Part of Speech tags and CFG parse trees. For ease of computation under limited resources, we will be using a fraction (10%) of the treebank corpus which is distributed with the **nltk** python library."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a4c4e6",
      "metadata": {
        "id": "41a4c4e6"
      },
      "source": [
        "## The Raw Data\n",
        "Download the data by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13da9ebc",
      "metadata": {
        "id": "13da9ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6040c882-a10c-49e8-afd5-3f3a5717ac66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
        "nltk.download('treebank')\n",
        "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bf62ed",
      "metadata": {
        "id": "a0bf62ed"
      },
      "source": [
        "Have a look at the first few examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106118f0",
      "metadata": {
        "id": "106118f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b8d5e2-f4b2-42a0-c59c-b3f31a342f8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])]),\n",
              " Tree('S', [Tree('NP-SBJ-1', [Tree('NP', [Tree('NNP', ['Rudolph']), Tree('NNP', ['Agnew'])]), Tree(',', [',']), Tree('UCP', [Tree('ADJP', [Tree('NP', [Tree('CD', ['55']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree('CC', ['and']), Tree('NP', [Tree('NP', [Tree('JJ', ['former']), Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NNP', ['Consolidated']), Tree('NNP', ['Gold']), Tree('NNP', ['Fields']), Tree('NNP', ['PLC'])])])])]), Tree(',', [','])]), Tree('VP', [Tree('VBD', ['was']), Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])])]), Tree('.', ['.'])])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "treebank.parsed_sents()[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5177c2f",
      "metadata": {
        "id": "c5177c2f"
      },
      "source": [
        "The parenthes encode a tree structure which can be pretty printed by calling a single example:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27023347",
      "metadata": {
        "id": "27023347"
      },
      "source": [
        "## Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f4c176",
      "metadata": {
        "id": "46f4c176"
      },
      "source": [
        "Next, we will prepare the data so it can be used to train our parser. For this part, please make yourself familiar with the [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html) module.\n",
        "\n",
        "Look at the following subtree."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treebank.parsed_sents()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "bu_UEC_5ZV-b",
        "outputId": "3ca33fce-d35e-47f6-9d71-dd3d1a9bb7a3"
      },
      "id": "bu_UEC_5ZV-b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP-SBJ-1', [Tree('NP', [Tree('NNP', ['Rudolph']), Tree('NNP', ['Agnew'])]), Tree(',', [',']), Tree('UCP', [Tree('ADJP', [Tree('NP', [Tree('CD', ['55']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree('CC', ['and']), Tree('NP', [Tree('NP', [Tree('JJ', ['former']), Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NNP', ['Consolidated']), Tree('NNP', ['Gold']), Tree('NNP', ['Fields']), Tree('NNP', ['PLC'])])])])]), Tree(',', [','])]), Tree('VP', [Tree('VBD', ['was']), Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])])]), Tree('.', ['.'])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"408px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,1552.0,408.0\" width=\"1552px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"50.5155%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ-1</text></svg><svg width=\"16.3265%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"56.25%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Rudolph</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"43.75%\" x=\"56.25%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Agnew</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.16327%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.06122%\" x=\"16.3265%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.8571%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.551%\" x=\"19.3878%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">UCP</text></svg><svg width=\"21.0526%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"68.75%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">55</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">years</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.375%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"31.25%\" x=\"68.75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">old</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.375%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.5263%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.57895%\" x=\"21.0526%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"24.3421%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.3684%\" x=\"27.6316%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32.7273%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"44.4444%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">former</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.2222%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"55.5556%\" x=\"44.4444%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.2222%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.3636%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"67.2727%\" x=\"32.7273%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"10.8108%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.40541%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"89.1892%\" x=\"10.8108%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"42.4242%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Consolidated</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.2121%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"18.1818%\" x=\"42.4242%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Gold</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.5152%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"24.2424%\" x=\"60.6061%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Fields</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"15.1515%\" x=\"84.8485%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PLC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.4242%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.4054%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.3636%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.8158%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.1633%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.06122%\" x=\"96.9388%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.4694%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.2577%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"47.9381%\" x=\"50.5155%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"5.37634%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">was</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"2.68817%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"94.6237%\" x=\"5.37634%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.95455%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">named</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.97727%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.0455%\" x=\"7.95455%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"9.87654%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-NONE-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">*-1</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.93827%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90.1235%\" x=\"9.87654%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-PRD</text></svg><svg width=\"38.3562%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"14.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">nonexecutive</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"39.2857%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.7143%\" x=\"64.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">director</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1429%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.1781%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.6438%\" x=\"38.3562%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"8.88889%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.44444%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"91.1111%\" x=\"8.88889%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"14.6341%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">this</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.31707%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"21.9512%\" x=\"14.6341%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">British</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.6098%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.2683%\" x=\"36.5854%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">industrial</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.2195%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"34.1463%\" x=\"65.8537%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">conglomerate</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.9268%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.4444%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.1781%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.9383%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.9773%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.6882%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.4845%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"1.54639%\" x=\"98.4536%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"99.2268%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7e23fb",
      "metadata": {
        "id": "4e7e23fb"
      },
      "source": [
        "First, note that nonterminals can have a variable number of children. However, in order for CKY to work, we require the data to be in Chomsky Normal Form (CNF), i.e. it needs to be binarized.\n",
        "We also want to simplify tags that have hyphens in them, and filter out -NONE- tags (which are used e.g. to indicate relative clauses).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc669f5",
      "metadata": {
        "id": "9bc669f5"
      },
      "source": [
        "### 1.1 Removing -NONE-, -RCB-, and -LRB- tags\n",
        "We want to remove `-NONE-`, `-LRB-` and `-RCB-` tags. For the sake of simplicity, we will remove any tree that contains these tags. Write a method that returns True if a tree passed to it contains such tags. In a comment (without implementing the code), give two other ways `-NONE-` tags could be handled more data efficiently without affecting the grammaticality of the sentence.\n",
        "\n",
        "\n",
        "*Find them and eliminate it*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d55a1f",
      "metadata": {
        "id": "12d55a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f2094d-a73a-4992-fe6f-388646240b83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from nltk import Tree\n",
        "\n",
        "bad_tags = ['-NONE-', '-LRB-', '-RCB-']\n",
        "\n",
        "def contains_none_tags(tree):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "\n",
        "    returns:\n",
        "        True iff the tree contains NONE, LRB or RCB tags.\n",
        "    \"\"\"\n",
        "    boolean = False\n",
        "\n",
        "    for pos in tree.treepositions():\n",
        "        # non-terminal symbols\n",
        "        if (type(tree[pos])!=str):\n",
        "            if tree[pos].label() in bad_tags:\n",
        "                boolean = True\n",
        "    return boolean\n",
        "\n",
        "contains_none_tags(treebank.parsed_sents()[5][0]) # this should return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0ee52e",
      "metadata": {
        "id": "aa0ee52e"
      },
      "source": [
        "### 1.2 Simplifying Functional Tags\n",
        "Write a method that takes in tags and only keeps the part before the first hyphen if it is hyphenated - e.g. `NP-SBJ` should become `NP`. Then write a method that traverses a tree and updates its tags in place.\n",
        "\n",
        "\n",
        "*We want to make the tag vocabulary smaller to make it fasteR*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003d7dd4",
      "metadata": {
        "id": "003d7dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "147783f1-f86f-4835-9f52-79c1273bfdd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,360.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"81.1765%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"62%\" x=\"38%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"38.7097%\" x=\"38.7097%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.8824%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.52941%\" x=\"96.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def simplify_functional_tag(tag):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        tag: string\n",
        "\n",
        "    returns:\n",
        "        the tag up to the first hyphen\n",
        "\n",
        "    \"\"\"\n",
        "    if tag in bad_tags:\n",
        "        return tag\n",
        "\n",
        "    else:\n",
        "        return tag.split('-')[0]\n",
        "\n",
        "def simplify_tags(tree):\n",
        "    \"\"\"\n",
        "    Traverses a parse tree and simplifies tags containing hyphens\n",
        "\n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "\n",
        "    returns:\n",
        "        parse tree with simplified tags (up to the first hyphen)\n",
        "    \"\"\"\n",
        "    for pos in tree.treepositions():\n",
        "        # non-terminal symbols\n",
        "        if (type(tree[pos])!=str):\n",
        "            tree[pos].set_label(simplify_functional_tag(tree[pos].label()))\n",
        "\n",
        "simplified_tree = treebank.parsed_sents()[1].copy(deep=True)\n",
        "simplify_tags(simplified_tree)\n",
        "simplified_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0b3cdf",
      "metadata": {
        "id": "7d0b3cdf"
      },
      "source": [
        "### 1.3 Binarizing the Parse Trees\n",
        "To remove unary derivations and convert the training trees to binary trees, we will use the functions `collapse_unary` and `chomsky_normal_form` in [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html). Write down the call you will make using horizontal markov smoothing of 1 and vertical markov smoothing of 0, factoring right, and using ^ for parent and | for child. **Explain the meaning and the purpose of these parameters in a comment**.\n",
        "\n",
        "*We need to binarize the parse trees: every node inside the tree has two children and the terminal node has exactly one child*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba69bf6",
      "metadata": {
        "id": "1ba69bf6"
      },
      "outputs": [],
      "source": [
        "from nltk.tree import collapse_unary, chomsky_normal_form\n",
        "\n",
        "def binarize(tree):\n",
        "    \"\"\"\n",
        "    Collapses unary productions and binarizes a parse tree in place.\n",
        "\n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "\n",
        "    returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    collapse_unary(tree)\n",
        "    chomsky_normal_form(tree,\n",
        "                        factor=\"right\",\n",
        "                        horzMarkov=1,\n",
        "                        vertMarkov=0,\n",
        "                        childChar=\"|\",\n",
        "                        parentChar=\"^\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binarized_tree = simplified_tree.copy(deep=True)\n",
        "binarize(binarized_tree)\n",
        "binarized_tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "S4R7LSNSo17b",
        "outputId": "8d844598-5f1e-4d92-c507-54b89f00eb18"
      },
      "id": "S4R7LSNSo17b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('S|<VP>', [Tree('VP', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree('NP|<,>', [Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NP|<NNP>', [Tree('NNP', ['Dutch']), Tree('NP|<VBG>', [Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])])])])]), Tree('.', ['.'])])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"552px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,552.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.7059%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S|&lt;VP&gt;</text></svg><svg width=\"95.8333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;,&gt;</text></svg><svg width=\"8.82353%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.41176%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"91.1765%\" x=\"8.82353%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"83.871%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;NNP&gt;</text></svg><svg width=\"26.9231%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.4615%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"73.0769%\" x=\"26.9231%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;VBG&gt;</text></svg><svg width=\"63.1579%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"36.8421%\" x=\"63.1579%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.5789%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.4615%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.4118%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.9167%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.16667%\" x=\"95.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.9167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.6471%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*every word in a sentence is a tuple of the word and annotation*"
      ],
      "metadata": {
        "id": "cr3OOK0rHW2j"
      },
      "id": "cr3OOK0rHW2j"
    },
    {
      "cell_type": "markdown",
      "id": "d60ddd21",
      "metadata": {
        "id": "d60ddd21"
      },
      "source": [
        "### 1.4 Run Data Preprocessing\n",
        "\n",
        "Bringing all of these together, write a method that takes a set of trees and returns a list of (copied) cleaned trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8b80f4",
      "metadata": {
        "id": "9d8b80f4"
      },
      "outputs": [],
      "source": [
        "def clean_trees(trees):\n",
        "    \"\"\"\n",
        "    Cleans parse trees from the penn treebank by performing tag simplification,\n",
        "        binarization, and filtering out trees with NONE tags.\n",
        "\n",
        "    parameters:\n",
        "        trees: parse trees\n",
        "\n",
        "    returns:\n",
        "        list of cleaned trees\n",
        "    \"\"\"\n",
        "    clean_trees = []\n",
        "\n",
        "    for t in trees:\n",
        "        tree = t.copy(deep=True)\n",
        "        simplify_tags(tree)\n",
        "        binarize(tree)\n",
        "        if not contains_none_tags(tree):\n",
        "            clean_trees.append(tree)\n",
        "\n",
        "    return clean_trees\n",
        "\n",
        "trees_cleaned = clean_trees(treebank.parsed_sents())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3ed7e9",
      "metadata": {
        "id": "5d3ed7e9"
      },
      "source": [
        "Now we can write the cleaned data to the disk to use as training and test data later (using an 80:20 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552b40d7",
      "metadata": {
        "id": "552b40d7"
      },
      "outputs": [],
      "source": [
        "def flatten(tree):\n",
        "    return tree._pformat_flat(\"\", \"()\", False)\n",
        "\n",
        "# 90-10 % split\n",
        "trees_train = trees_cleaned[:886]\n",
        "trees_test = trees_cleaned[886:]\n",
        "\n",
        "with open(\"data/train.clean\", \"w\") as f:\n",
        "    for tree in trees_train:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")\n",
        "\n",
        "with open(\"data/test.clean\", \"w\") as f:\n",
        "    for tree in trees_test:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb16456e",
      "metadata": {
        "id": "cb16456e"
      },
      "source": [
        "# 2. Neural Constituency Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c51466e",
      "metadata": {
        "id": "6c51466e"
      },
      "source": [
        "Now we want to train our model to parse from scratch, by providing it with training examples and optimizing it.\n",
        "We will use a bidirectional LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a4ed8e",
      "metadata": {
        "id": "47a4ed8e"
      },
      "source": [
        "## Defining the vocabulary\n",
        "First, load the training and test data we created in part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5ea1fa",
      "metadata": {
        "id": "3e5ea1fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d0a2d5-a0b8-41f8-c30f-d2a5e1518764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 886 training examples.\n",
            "Loaded 100 test examples.\n",
            "Processing trees for training...\n"
          ]
        }
      ],
      "source": [
        "from src import trees\n",
        "\n",
        "train_path = \"data/train.clean\"\n",
        "test_path = \"data/test.clean\"\n",
        "\n",
        "train_treebank = trees.load_trees(train_path)\n",
        "test_treebank = trees.load_trees(test_path)\n",
        "\n",
        "print(f\"Loaded {len(train_treebank)} training examples.\")\n",
        "print(f\"Loaded {len(test_treebank)} test examples.\")\n",
        "\n",
        "print(\"Processing trees for training...\")\n",
        "train_parse = [tree.convert() for tree in train_treebank]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_parse[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgGCHXez8YCo",
        "outputId": "9dea7825-3ceb-4837-a3b2-ddeb349cdd2a"
      },
      "id": "sgGCHXez8YCo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<src.trees.InternalParseNode at 0x7f73b9d2e5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79309372",
      "metadata": {
        "id": "79309372"
      },
      "source": [
        "Then, we collect the vocabulary for words, tags, and labels from the training data, creating a reverse index to look up the index of words in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649df1a4",
      "metadata": {
        "id": "649df1a4"
      },
      "outputs": [],
      "source": [
        "from src import vocabulary\n",
        "\n",
        "START = \"<START>\"\n",
        "STOP = \"<STOP>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "tag_vocab = vocabulary.Vocabulary()\n",
        "tag_vocab.index(START)\n",
        "tag_vocab.index(STOP)\n",
        "\n",
        "word_vocab = vocabulary.Vocabulary()\n",
        "word_vocab.index(START)\n",
        "word_vocab.index(STOP)\n",
        "word_vocab.index(UNK)\n",
        "\n",
        "label_vocab = vocabulary.Vocabulary()\n",
        "label_vocab.index(())\n",
        "\n",
        "for tree in train_parse:\n",
        "    nodes = [tree]\n",
        "    while nodes:\n",
        "        node = nodes.pop()\n",
        "        if isinstance(node, trees.InternalParseNode):\n",
        "            label_vocab.index(node.label)\n",
        "            nodes.extend(reversed(node.children))\n",
        "            print(node.label)\n",
        "        else:\n",
        "            tag_vocab.index(node.tag)\n",
        "            word_vocab.index(node.word)\n",
        "\n",
        "tag_vocab.freeze()\n",
        "word_vocab.freeze()\n",
        "label_vocab.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_vocab.values"
      ],
      "metadata": {
        "id": "X2ez4lg45Yue"
      },
      "id": "X2ez4lg45Yue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_vocab.values"
      ],
      "metadata": {
        "id": "Y4RJDcxj5RsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7363ac-80ae-4926-9df2-4d85c69bd3c1"
      },
      "id": "Y4RJDcxj5RsS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START>',\n",
              " '<STOP>',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'CD',\n",
              " 'NNS',\n",
              " 'JJ',\n",
              " 'MD',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " '.',\n",
              " 'VBZ',\n",
              " 'VBG',\n",
              " 'VBD',\n",
              " '``',\n",
              " 'PRP',\n",
              " 'VBP',\n",
              " 'EX',\n",
              " 'PRP$',\n",
              " 'RB',\n",
              " \"''\",\n",
              " 'CC',\n",
              " 'VBN',\n",
              " 'POS',\n",
              " 'TO',\n",
              " 'JJS',\n",
              " 'JJR',\n",
              " ':',\n",
              " 'RP',\n",
              " 'RBR',\n",
              " 'NNPS',\n",
              " 'WRB',\n",
              " 'RBS',\n",
              " 'PDT',\n",
              " 'LS',\n",
              " 'FW',\n",
              " 'WP',\n",
              " '$']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vocab.values"
      ],
      "metadata": {
        "id": "8I492sZ54vUg"
      },
      "id": "8I492sZ54vUg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f0fefeb6",
      "metadata": {
        "id": "f0fefeb6"
      },
      "source": [
        "## Defining the model\n",
        "Now, we will define the neural network model that will predict label scores for spans. The reference implementation uses a bidirectional LSTM which you can define using dynet's [BiRNNBuilder class](https://dynet.readthedocs.io/en/latest/python_ref.html#dynet.BiRNNBuilder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4100b9",
      "metadata": {
        "id": "6e4100b9"
      },
      "outputs": [],
      "source": [
        "import dynet as dy\n",
        "from src.util import Feedforward\n",
        "\n",
        "dy.reset_random_seed(42)\n",
        "\n",
        "# Create a dynet model\n",
        "model = dy.ParameterCollection()\n",
        "parser_model = model.add_subcollection(\"Parser\")\n",
        "\n",
        "batch_size = 10\n",
        "tag_embedding_dim = 50\n",
        "word_embedding_dim = 100\n",
        "lstm_layers = 2\n",
        "lstm_dim = 250\n",
        "label_hidden_dim = 250\n",
        "dropout = 0.4\n",
        "\n",
        "tag_embeddings = parser_model.add_lookup_parameters((tag_vocab.size, tag_embedding_dim))\n",
        "word_embeddings = parser_model.add_lookup_parameters((word_vocab.size, word_embedding_dim))\n",
        "\n",
        "# Create a lstm using the dynet BiRNNBuilder\n",
        "lstm = dy.BiRNNBuilder(\n",
        "    lstm_layers,\n",
        "    tag_embedding_dim + word_embedding_dim,\n",
        "    2 * lstm_dim,\n",
        "    parser_model,\n",
        "    dy.VanillaLSTMBuilder)\n",
        "\n",
        "# Define a Feedforward neural net that predicts the label probabilities given lstm outputs from a sentence\n",
        "f_label = Feedforward(parser_model, 2 * lstm_dim, [label_hidden_dim], label_vocab.size - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9fdaa53",
      "metadata": {
        "id": "e9fdaa53"
      },
      "source": [
        "## 2.1 Generating Embeddings\n",
        "\n",
        "Next we need to convert the words and tags into embeddings that can be fed to the LSTM. Implement the following method.\n",
        "Unknown words should get the embedding of the UNK word.\n",
        "\n",
        "Hint: use the reverse index methods `tag_vocab.index()` and `word_vocab.index()` methods from `vocabulary.py` to find the keys of words and tags in the respective embedding dicts created above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_vocab.values"
      ],
      "metadata": {
        "id": "ZPSTOTVQEC4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a7253f-de83-47f0-a928-7dd2aa06899a"
      },
      "id": "ZPSTOTVQEC4X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START>',\n",
              " '<STOP>',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'CD',\n",
              " 'NNS',\n",
              " 'JJ',\n",
              " 'MD',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " '.',\n",
              " 'VBZ',\n",
              " 'VBG',\n",
              " 'VBD',\n",
              " '``',\n",
              " 'PRP',\n",
              " 'VBP',\n",
              " 'EX',\n",
              " 'PRP$',\n",
              " 'RB',\n",
              " \"''\",\n",
              " 'CC',\n",
              " 'VBN',\n",
              " 'POS',\n",
              " 'TO',\n",
              " 'JJS',\n",
              " 'JJR',\n",
              " ':',\n",
              " 'RP',\n",
              " 'RBR',\n",
              " 'NNPS',\n",
              " 'WRB',\n",
              " 'RBS',\n",
              " 'PDT',\n",
              " 'LS',\n",
              " 'FW',\n",
              " 'WP',\n",
              " '$']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3895e3",
      "metadata": {
        "id": "2a3895e3"
      },
      "outputs": [],
      "source": [
        "def convert_to_embeddings(sentence):\n",
        "    \"\"\"\n",
        "    Converts a sentence consisting of tags and words into embeddings.\n",
        "        Replaces words not in the vocabulary with with the UNK placeholder.\n",
        "\n",
        "    params:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "\n",
        "    return:\n",
        "        dy expression containing a concatenation of all tag embedding/word embedding pairs\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for tag, word in [(START, START)] + sentence + [(STOP, STOP)]:\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "        if word not in word_vocab.values:\n",
        "            word = UNK\n",
        "\n",
        "        tag_embedding = tag_embeddings[tag_vocab.index(tag)]\n",
        "        word_embedding = word_embeddings[word_vocab.index(word)]\n",
        "        ### YOUR CODE END\n",
        "\n",
        "        embeddings.append(dy.concatenate([tag_embedding, word_embedding]))\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test your code, run the following cell on the sentence `The boy ate a pie` with tags ['DT', 'NN', 'VBZ' 'DT', 'NN']:"
      ],
      "metadata": {
        "id": "FedYhfo9q8Df"
      },
      "id": "FedYhfo9q8Df"
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "embeddings = convert_to_embeddings(sentence)\n",
        "assert len(embeddings)==7\n",
        "assert len(embeddings[0].value())==150\n",
        "assert embeddings[5].value() == dy.concatenate(\n",
        "    [tag_embeddings[tag_vocab.index('NN')],\n",
        "     word_embeddings[word_vocab.index(UNK)]]).value()"
      ],
      "metadata": {
        "id": "09cTYZ1Tq8de"
      },
      "id": "09cTYZ1Tq8de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b5eb2e53",
      "metadata": {
        "id": "b5eb2e53"
      },
      "source": [
        "We can now use the above method to get the lstm outputs for the whole sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d09015f",
      "metadata": {
        "id": "3d09015f"
      },
      "outputs": [],
      "source": [
        "def get_lstm_outputs(sentence, is_train):\n",
        "    \"\"\"\n",
        "    Gets the outputs of the lstm for a given sentence.\n",
        "\n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "\n",
        "    returns:\n",
        "        lstm_outputs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if is_train:\n",
        "        lstm.set_dropout(dropout)\n",
        "    else:\n",
        "        lstm.disable_dropout()\n",
        "\n",
        "    # Get the tag and word embeddings for the sentence\n",
        "    embeddings = convert_to_embeddings(sentence)\n",
        "\n",
        "    # Get the output of the LSTM given the embedded sentence\n",
        "    lstm_outputs = lstm.transduce(embeddings)\n",
        "\n",
        "    return lstm_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcfc975",
      "metadata": {
        "id": "6bcfc975"
      },
      "source": [
        "The following two methods are helper methods which compute the scores for each label given a span."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8314af",
      "metadata": {
        "id": "bf8314af"
      },
      "outputs": [],
      "source": [
        "from src.util import augment\n",
        "\n",
        "def get_span_encoding(left, right, lstm_outputs):\n",
        "    \"\"\"\n",
        "    Computes the encoding of a sentence span (substring between two indices)\n",
        "        given the forward and backward outputs in the LSTM.\n",
        "\n",
        "    parameters:\n",
        "        left: left span index\n",
        "        right: right span index\n",
        "\n",
        "    returns:\n",
        "        encoding of the span\n",
        "    \"\"\"\n",
        "    forward = (\n",
        "        lstm_outputs[right][:lstm_dim] -\n",
        "        lstm_outputs[left][:lstm_dim])\n",
        "    backward = (\n",
        "        lstm_outputs[left + 1][lstm_dim:] -\n",
        "        lstm_outputs[right + 1][lstm_dim:])\n",
        "    return dy.concatenate([forward, backward])\n",
        "\n",
        "def get_label_scores(left, right, lstm_outputs, gold, force_gold):\n",
        "    \"\"\"\n",
        "    Computes the best label for a given span and its score.\n",
        "\n",
        "    parameters:\n",
        "        left: left index of the span\n",
        "        right: right index of the span\n",
        "        lstm_outputs: outputs of the lstm when given the sentence\n",
        "        gold reference parse tree for the sentence\n",
        "        force_gold: True if method should construct the gold parse tree\n",
        "          and compute its score\n",
        "\n",
        "    returns:\n",
        "        (label, score):\n",
        "            label: the highest scoring label if force_gold is False,\n",
        "              or the gold label if force_gold is true\n",
        "            score: the score of the label\n",
        "    \"\"\"\n",
        "    is_train = gold is not None\n",
        "\n",
        "    label_scores = f_label(get_span_encoding(left, right, lstm_outputs))\n",
        "    label_scores = dy.concatenate([dy.zeros(1), label_scores])\n",
        "\n",
        "    if is_train:\n",
        "        oracle_label = gold.oracle_label(left, right)\n",
        "        oracle_label_index = label_vocab.index(oracle_label)\n",
        "\n",
        "    if force_gold:\n",
        "        label_score = label_scores[oracle_label_index]\n",
        "        label = oracle_label\n",
        "\n",
        "    else:\n",
        "        if is_train:\n",
        "            label_scores = augment(label_scores, oracle_label_index)\n",
        "        label_scores_np = label_scores.npvalue()\n",
        "        span = right - left\n",
        "        argmax_label_index = int(\n",
        "                        label_scores_np.argmax() if span < len(sentence) else\n",
        "                        label_scores_np[1:].argmax() + 1)\n",
        "        label = label_vocab.value(argmax_label_index)\n",
        "        label_score = label_scores[argmax_label_index]\n",
        "    return label, label_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fadb8972",
      "metadata": {
        "id": "fadb8972"
      },
      "source": [
        "## 2.2 CKY with estimated label probabilites\n",
        "Now we can implement the parser method. It works like CKY, with some additions.\n",
        "\n",
        "During training, the `gold` parameter is set, representing the reference parse tree. During inference, this is not set and the method simply returns the best scoring parse tree.\n",
        "\n",
        "Your task is to implement the CKY algorithm, iterating through spans and for each pair of span indices dynamically calculate scores and parse trees:\n",
        "1. Use the method `get_label_scores(left, right, lstm_outputs, gold, force_gold)` to get the scores for each label corresponding to the given span (left, right).\n",
        "2. Find the best place to split a given span into two subspans given their respective label scores. (If `force_gold` is set, use the method `tree.oracle_splits(left, right)` from `trees.py` to get the split positions, and use the first of them as the index to split the tree.)\n",
        "3. Calculate the score of the label when splitting at the best index found above and put it into the scores `chart`.\n",
        "4. Get the subtrees for the span and split position, and put the resulting new subtree into the `parse_trees` dict.\n",
        "\n",
        "*Hint: the label scores are stored as dynet expressions, use `.value()` to get the score value.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We estimate a score for each span, and, if that score is high enough, give it a label. This is all done through the get_label_scores method, so we only need to figure out how to compute the score by splitting the chart to maximise the score.\n",
        "\n",
        "\n",
        "Hint for 2.b) ii): If you don't get a label for an entry in the parse_tree chart, just concatenate the lists of child trees and store that new list in the chart instead\n",
        "\n",
        "Another thing for 2.b) ii): the gold_tree parameter tells the method that computes the label scores that it is currently training which changes how it computes the scores. So including that parameter for training will yield a better result in the end.\n",
        "\n",
        "The sum of a single parse tree is the sum of span scores (Computed in CKY style). --> adding the highest sum of two sub-span scores plus the score of the span itself."
      ],
      "metadata": {
        "id": "DaY5ezQ4hp2E"
      },
      "id": "DaY5ezQ4hp2E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb42e8f",
      "metadata": {
        "id": "4fb42e8f"
      },
      "outputs": [],
      "source": [
        "from src import trees\n",
        "\n",
        "def parse(sentence, gold=None, force_gold=False):\n",
        "    \"\"\"\n",
        "    Generates the best scoring parse tree for a given sentence.\n",
        "\n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold: gold reference parse tree for the sentence\n",
        "        force_gold: If true, method will construct the gold parse tree\n",
        "            and compute its score, otherwise it will compute the\n",
        "            best scoring parse tree.\n",
        "\n",
        "    returns:\n",
        "        (tree, score):\n",
        "            tree: constructed best or gold parse tree\n",
        "            score: score of the constructed parse tree\n",
        "    \"\"\"\n",
        "    N = len(sentence)\n",
        "\n",
        "    chart = {}\n",
        "    parse_trees = {}\n",
        "\n",
        "    is_train = gold is not None\n",
        "    lstm_outputs = get_lstm_outputs(sentence, is_train)\n",
        "\n",
        "    for i in range(N):\n",
        "        tag, word = sentence[i]\n",
        "        label, score = get_label_scores(i, i + 1, lstm_outputs, gold, force_gold)\n",
        "        tree = trees.LeafParseNode(i, tag, word)\n",
        "        if label:\n",
        "            tree = trees.InternalParseNode(label, [tree])\n",
        "        parse_trees[i, i + 1] = [tree]\n",
        "        chart[i, i + 1] = score\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    for span in range(2, N+1):\n",
        "        # i marks the beginning of the span\n",
        "        # k marks the end of the span\n",
        "        # j marks the splitting point of the span\n",
        "\n",
        "        for i in range(N-span+1):\n",
        "            k = i + span\n",
        "            # compute the score of the span and the label if the score is high enough\n",
        "            label, score = get_label_scores(i, k, lstm_outputs, gold, force_gold)\n",
        "\n",
        "            # if there is a gold_tree\n",
        "            if force_gold:\n",
        "                split = gold.oracle_splits(i, k)[0]\n",
        "\n",
        "            else:\n",
        "                # look for the split that gets the highest addition of subspan scores\n",
        "                scores = []\n",
        "                for j in range(i+1, k):\n",
        "                    sub_score = chart[i, j] + chart[j, k]\n",
        "                    scores.append(sub_score.value())\n",
        "\n",
        "                split = i + scores.index(max(scores)) + 1\n",
        "\n",
        "            subtree1 = parse_trees[i, split]\n",
        "            subtree2 = parse_trees[split, k]\n",
        "\n",
        "            if label:\n",
        "                tree = [trees.InternalParseNode(label, subtree1 + subtree2)]\n",
        "            else:\n",
        "                tree = subtree1 + subtree2\n",
        "\n",
        "            # adding the highest sum of two sub-span scores plus the score of the span itself\n",
        "            chart[i, k] = chart[i, split] + chart[split, k] + score\n",
        "            parse_trees[i, k] = tree\n",
        "\n",
        "    ### YOUR CODE END\n",
        "\n",
        "    assert len(parse_trees[0, N]) == 1\n",
        "    tree = parse_trees[0, N][0]\n",
        "    score = chart[0, N]\n",
        "    return tree, score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "tree, score =  parse(sentence)\n",
        "score.value()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Humb3QaV4WF",
        "outputId": "ae9fa980-54a7-47cb-a304-d66cab51b2f0"
      },
      "id": "6Humb3QaV4WF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dy.parameter(...) call is now DEPRECATED.\n",
            "        There is no longer need to explicitly add parameters to the computation graph.\n",
            "        Any used parameter will be added automatically.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4991785287857056"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your code on the sentence from before. Don't worry if the parse tree does not make sense right now, since the model has not been trained yet. You should get the following tree and score:\n",
        "\n",
        "`tree:  (S|<ADJP> (S|<ADJP> (S|<ADJP> (DT The)) (S|<ADJP> (S|<ADJP> (NN boy)) (S|<ADJP> (S|<ADJP> (VBZ ate)) (S|<ADJP> (DT a))))) (S|<ADJP> (NN pie)))`\n",
        "\n",
        "`score:  1.4991785287857056`"
      ],
      "metadata": {
        "id": "oxIxXPz_rro3"
      },
      "id": "oxIxXPz_rro3"
    },
    {
      "cell_type": "markdown",
      "id": "03e04c2e",
      "metadata": {
        "id": "03e04c2e"
      },
      "source": [
        "## 2.3 Training the model\n",
        "\n",
        "Now we can train our model on the training data. Your first task is to implement a method that calculates the loss for a predicted parse tree given a sentence.\n",
        "\n",
        "Do this by first calculating the score and predicted parse tree, then calulating the score of a given gold parse tree.\n",
        "\n",
        "You should implement hinge loss where the loss is 0 if the predicted tree was correct and otherwise the difference between the score of the predicted tree and that of the reference tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c088e03",
      "metadata": {
        "id": "0c088e03"
      },
      "outputs": [],
      "source": [
        "def hinge_loss(sentence, gold_tree):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold_tree: gold reference parse tree for the sentence\n",
        "\n",
        "    returns:\n",
        "        dynet expression containing the loss, i.e. dy.zeros(1) if correct and\n",
        "        difference between parse and oracle score if incorrect.\n",
        "    \"\"\"\n",
        "\n",
        "    tree, score = parse(sentence)\n",
        "    gold_tree, gold_score = parse(sentence, gold=gold_tree, force_gold=True)\n",
        "\n",
        "    loss = score - gold_score\n",
        "\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09847de5",
      "metadata": {
        "id": "09847de5"
      },
      "source": [
        "Now run training for 10 epochs, reporting the batch loss for each batch.\n",
        "\n",
        "You should iterate through the trees, extract the input sentence from the tree and generate the loss for each of them using the loss function defined above. Then add the loss to the `batch_losses` list and increase the `total_processed` counter at every sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca5b938",
      "metadata": {
        "id": "dca5b938"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from src.util import format_elapsed\n",
        "\n",
        "np.random.seed(1)\n",
        "trainer = dy.AdamTrainer(model)\n",
        "total_processed = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(10):\n",
        "    np.random.shuffle(train_parse)\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for start_index in range(0, len(train_parse)-batch_size, batch_size):\n",
        "        dy.renew_cg()\n",
        "        # YOUR CODE HERE\n",
        "        batch_losses = []\n",
        "\n",
        "        for i in range(start_index, start_index + batch_size):\n",
        "            tree = train_parse[i]\n",
        "            sentence = [(str(leaf.tag), str(leaf.word)) for leaf in tree.leaves()]\n",
        "            batch_losses.append(hinge_loss(sentence, tree))\n",
        "            total_processed +=1\n",
        "\n",
        "        # YOUR CODE END\n",
        "        batch_loss = dy.average(batch_losses)\n",
        "        batch_loss_value = batch_loss.scalar_value()\n",
        "        batch_loss.backward()\n",
        "        trainer.update()\n",
        "\n",
        "        print(\n",
        "            \"epoch {:,} \"\n",
        "            \"batch {:,}/{:,} \"\n",
        "            \"processed {:,} \"\n",
        "            \"batch-loss {:.4f} \"\n",
        "            \"epoch-elapsed {} \"\n",
        "            \"total-elapsed {}\".format(\n",
        "                epoch,\n",
        "                start_index // batch_size + 1,\n",
        "                int(np.ceil(len(train_parse) / batch_size)),\n",
        "                total_processed,\n",
        "                batch_loss_value,\n",
        "                format_elapsed(epoch_start_time),\n",
        "                format_elapsed(start_time),\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907f3df6",
      "metadata": {
        "id": "907f3df6"
      },
      "source": [
        "### Evaluating the model\n",
        "Evaluate the model and report the Recall, Precision, and F-Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eac5620",
      "metadata": {
        "id": "4eac5620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a72651a-e04a-4669-899b-52b9b9a46d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev-fscore (Recall=0.43, Precision=0.39, FScore=0.41) \n"
          ]
        }
      ],
      "source": [
        "from src import evaluate\n",
        "\n",
        "evalb_dir = \"EVALB/\"\n",
        "!chmod +x EVALB/evalb\n",
        "\n",
        "test_predicted = []\n",
        "for tree in test_treebank:\n",
        "    dy.renew_cg()\n",
        "    sentence = [(leaf.tag, leaf.word) for leaf in tree.leaves()]\n",
        "    predicted, _ = parse(sentence, None, False)\n",
        "    test_predicted.append(predicted.convert())\n",
        "\n",
        "test_fscore = evaluate.evalb(evalb_dir, test_treebank, test_predicted)\n",
        "\n",
        "print(f\"dev-fscore {test_fscore} \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nNE71y7-sYm"
      },
      "id": "1nNE71y7-sYm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "parsing",
      "language": "python",
      "name": "parsing"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}